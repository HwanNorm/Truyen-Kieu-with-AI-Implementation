{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17df9dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authorship Attribution Analysis\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.preprocessor import KieuPreprocessor\n",
    "from src.vectorizer import TfidfVectorizer\n",
    "from src.authorship import AuthorshipClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load Truyện Kiều\n",
    "preprocessor = KieuPreprocessor(stopwords_file='../data/vietnamese_stopwords.txt')\n",
    "verses = preprocessor.load_poem('../data/truyen_kieu.txt')\n",
    "tokenized_verses = preprocessor.preprocess_all_verses(verses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82efe3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF matrix\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(tokenized_verses)\n",
    "\n",
    "# For demonstration, we'll simulate having comparison texts\n",
    "# In a real scenario, you would load actual comparison texts\n",
    "\n",
    "# Create synthetic data for demonstration\n",
    "# 1 = Nguyễn Du, 0 = Not Nguyễn Du\n",
    "# Normally, you'd load real comparison texts from other authors\n",
    "labels = np.ones(len(verses))  # All verses from Truyện Kiều are by Nguyễn Du\n",
    "\n",
    "# For demonstration, let's pretend some random verses are not by Nguyễn Du\n",
    "np.random.seed(42)\n",
    "random_indices = np.random.choice(len(verses), size=int(len(verses)*0.3), replace=False)\n",
    "labels[random_indices] = 0\n",
    "\n",
    "# Initialize authorship classifier\n",
    "classifier = AuthorshipClassifier()\n",
    "\n",
    "# Extract features\n",
    "features = classifier.extract_features(tfidf_matrix, tokenized_verses)\n",
    "\n",
    "# Train the classifier\n",
    "classifier.train(features, labels)\n",
    "\n",
    "# Test on some \"unknown\" verses\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "predictions, confidence = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89bb839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confidence scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(confidence, bins=20)\n",
    "plt.axvline(0.5, color='red', linestyle='--')\n",
    "plt.title('Distribution of Confidence Scores')\n",
    "plt.xlabel('Confidence Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Display sample predictions\n",
    "print(\"Sample predictions:\")\n",
    "for i in range(10):\n",
    "    idx = np.random.randint(0, len(X_test))\n",
    "    verse_idx = int(idx / len(features) * len(verses))\n",
    "    auth = \"Nguyễn Du\" if predictions[idx] == 1 else \"Not Nguyễn Du\"\n",
    "    print(f\"Verse: {verses[verse_idx]}\")\n",
    "    print(f\"Prediction: {auth} (confidence: {confidence[idx]:.4f})\")\n",
    "    print(f\"Actual: {'Nguyễn Du' if y_test[idx] == 1 else 'Not Nguyễn Du'}\")\n",
    "    print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
